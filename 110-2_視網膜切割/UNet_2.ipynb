{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UExlaK4jXZSM"
   },
   "source": [
    "https://www.youtube.com/watch?v=T0BiFBaMLDQ&t=215s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsZbxSlrTvAZ"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5UUTxYZpXXFo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import imageio\n",
    "# from albumentations import HorizontalFlip, VerticalFlip, Rotate # !!!!\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"儲存csv\"\"\"\n",
    "# import pandas as pd\n",
    "# a=pd.DataFrame(X1)\n",
    "# a.to_csv(\"X1_ground.csv\")\n",
    "\"\"\"Load npy檔\"\"\"\n",
    "# Y1 = np.load(os.path.join(dataset,\"Y1_predict.npy\"))\n",
    "\"\"\"Save npy檔\"\"\"\n",
    "# np.save(\"data_train.npy\",data_train)\n",
    "\"\"\"模型\"\"\"\n",
    "def save_model(model,filename):\n",
    "    state = model.state_dict()\n",
    "    for key in state: state[key] = state[key].clone().cpu()\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def load_model(model,filename):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jatr7qIzad4B"
   },
   "outputs": [],
   "source": [
    "# !unzip dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qhdbnc__XxXs"
   },
   "outputs": [],
   "source": [
    "# Create a directory\n",
    "def create_directory(path):\n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "def load_data(path):\n",
    "  train_x = sorted(glob(os.path.join(path,'train','images','*.tif'))) # training photo\n",
    "  train_y = sorted(glob(os.path.join(path,'train','mask','*.gif'))) # training mask\n",
    "\n",
    "  test_x = sorted(glob(os.path.join(path,'test','images','*.tif'))) # training photo\n",
    "  test_y = sorted(glob(os.path.join(path,'test','mask','*.gif'))) # training mask\n",
    "\n",
    "  return ((train_x, train_y), (test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "C0hCG3COhKyz"
   },
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "  size = (512, 512)\n",
    "  \n",
    "  for idx, (x,y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "    # 抽出必要的字詞\n",
    "    name = x.split('/')[-1].split('.')[0] # ['', 'content', 'dataset', 'train', 'images', '21_training.tif'] 負一 只取最後一項\n",
    "    \n",
    "    # read image and mask\n",
    "    x = cv2.imread(x,cv2.IMREAD_COLOR) # (584, 565, 3)\n",
    "    y = imageio.mimread(y)[0] # (584, 565)\n",
    "\n",
    "    # 處理augmentation\n",
    "    if augment == True:\n",
    "      aug = HorizontalFlip(p=1.0)\n",
    "      augmented = aug(image=x, mask=y)\n",
    "      x1 = augmented['image']\n",
    "      y1 = augmented['mask']\n",
    "\n",
    "      aug = VerticalFlip(p=1.0)\n",
    "      augmented = aug(image=x, mask=y)\n",
    "      x2 = augmented['image']\n",
    "      y2 = augmented['mask']\n",
    "\n",
    "      aug = Rotate(limit=45,p=1.0) # degree for rotation !!!\n",
    "      augmented = aug(image=x, mask=y)\n",
    "      x3 = augmented['image']\n",
    "      y3 = augmented['mask']\n",
    "\n",
    "      X = [x,x1,x2,x3]\n",
    "      Y = [y,y1,y2,y3]\n",
    "\n",
    "      pass\n",
    "\n",
    "    else:\n",
    "      X = [x]  ### ????\n",
    "      Y = [y]\n",
    "\n",
    "    # 重新命名放入new_data資料夾\n",
    "    index = 0\n",
    "    for i,j in zip(X,Y):\n",
    "      i = cv2.resize(i,size) # 改變大小\n",
    "      j = cv2.resize(j,size)\n",
    "\n",
    "      tmp_img = f'{name}_{index}.png' # 21_training_0.png\n",
    "      tmp_mask = f'{name}_{index}.png'\n",
    "\n",
    "      image_path = os.path.join(save_path,'images',tmp_img) \n",
    "      mask_path = os.path.join(save_path,'mask',tmp_mask)\n",
    "\n",
    "      cv2.imwrite(image_path, i) # 寫入資料夾\n",
    "      cv2.imwrite(mask_path, j)\n",
    "\n",
    "      index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ib8m1a7Satpo",
    "outputId": "4a8eb5a4-e4b5-460c-ccf2-1b37ea8c6598"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "  # Random Seed\n",
    "  np.random.seed(42)\n",
    "  # Load Data\n",
    "  data_path = '/content/dataset'\n",
    "  ((train_x, train_y), (test_x,test_y)) = load_data(data_path)\n",
    "\n",
    "  print('datasest files len:',len(train_x),len(train_y),len(test_x),len(test_y))\n",
    "\n",
    "  # Create folder for new augmentation data\n",
    "  create_directory('/content/new_data/train/images/')\n",
    "  create_directory('/content/new_data/train/mask/')\n",
    "  create_directory('/content/new_data/test/images/')\n",
    "  create_directory('/content/new_data/test/mask/')\n",
    "\n",
    "  # Do augmentation\n",
    "  augment_data(train_x, train_y, '/content/new_data/train/', augment= True)\n",
    "  augment_data(test_x, test_y, '/content/new_data/test/', augment= False) # 為甚麼不用test_x,y???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fO818qWFbS1N"
   },
   "outputs": [],
   "source": [
    "# !zip -r /content/new_data.zip /content/new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6wktYIrTzFf"
   },
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PrnVfeMaT0_w"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b35jllFwT5xe"
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "  def __init__(self, in_c, out_c):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "    self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(out_c)\n",
    "    \n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    x = self.conv1(inputs) # [2, 64, 128, 128] 奇怪kernel size 不是3嗎\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    x = self.conv2(x) # [2, 64, 128, 128]\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "  def __init__(self, in_c, out_c):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv = conv_block(in_c, out_c)\n",
    "    self.pool = nn.MaxPool2d((2,2)) \n",
    "\n",
    "  def forward(self, inputs):\n",
    "    x = self.conv(inputs)\n",
    "    p = self.pool(x) \n",
    "\n",
    "    return x, p\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "  def __init__(self, in_c, out_c):\n",
    "    super().__init__()\n",
    "\n",
    "    self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0) # upsampling?\n",
    "    self.conv = conv_block(out_c+out_c, out_c) # 加上encoder的layer\n",
    "\n",
    "  def forward(self, inputs, skip):\n",
    "    x = self.up(inputs)\n",
    "    x = torch.cat([x, skip], axis=1) # 加上encoder的layer # pytorch第一軸是channel (tensorflow第-1軸)\n",
    "    x = self.conv(x)\n",
    "    return x\n",
    "\n",
    "class build_unet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # Encoder\n",
    "    self.e1 = encoder_block(3,64)\n",
    "    self.e2 = encoder_block(64,128)\n",
    "    self.e3 = encoder_block(128,256)\n",
    "    self.e4 = encoder_block(256,512)\n",
    "\n",
    "    # BottleNeck\n",
    "    self.b = conv_block(512, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    self.d1 = decoder_block(1024, 512)\n",
    "    self.d2 = decoder_block(512, 256)\n",
    "    self.d3 = decoder_block(256, 128)\n",
    "    self.d4 = decoder_block(128, 64)\n",
    "\n",
    "    # Classifier 二元分類 channel=1\n",
    "    self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    # Encoder\n",
    "    s1, p1 = self.e1(inputs) # [2, 64, 512, 512]\n",
    "    s2, p2 = self.e2(p1) # [2, 128, 256, 256]\n",
    "    s3, p3 = self.e3(p2) # [2, 256, 128, 128]\n",
    "    s4, p4 = self.e4(p3) # [2, 512, 64, 64]\n",
    "\n",
    "    # BottleNeck\n",
    "    b = self.b(p4) # [2, 1024, 32, 32]\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = self.d1(b, s4) # s for skip block\n",
    "    d2 = self.d2(d1, s3)\n",
    "    d3 = self.d3(d2, s2)\n",
    "    d4 = self.d4(d3, s1)\n",
    "\n",
    "    outputs = self.outputs(d4)\n",
    "    # print(outputs.shape)\n",
    "\n",
    "\n",
    "    # print(s1.shape,s2.shape,s3.shape,s4.shape,b.shape)\n",
    "\n",
    "\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(chann_in, chann_out, k_size, p_size):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Conv2d(chann_in, chann_out, kernel_size=k_size, padding=p_size),\n",
    "        nn.BatchNorm2d(chann_out),\n",
    "        nn.ReLU()\n",
    "        # nn.Sigmoid()\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):\n",
    "\n",
    "    layers = [ conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list)) ]\n",
    "    # 2, 64, 512, 512\n",
    "    # layers = layers + [ nn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s)]\n",
    "    # 2, 64, 256, 256\n",
    "\n",
    "    return nn.Sequential(*layers) #  list-like layer\n",
    "\n",
    "def vgg_fc_layer(size_in, size_out):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Linear(size_in, size_out),\n",
    "        nn.BatchNorm1d(size_out),\n",
    "        nn.ReLU()\n",
    "        # nn.Sigmoid()\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        # Conv blocks (BatchNorm + ReLU activation added in each block)\n",
    "        self.layer1 = vgg_conv_block([3,64], [64,64], [3,3], [1,1], 2, 2)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
    "        self.max4 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
    "        self.max5 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        # FC layers\n",
    "        self.layer6 = vgg_fc_layer(16*16*512, 4096) # 長x寬xfeature 數\n",
    "        self.layer7 = vgg_fc_layer(4096, 4096)\n",
    "\n",
    "        # Interpolation\n",
    "        self.inter = Interpolate(size=(512, 512), mode='bilinear')\n",
    "\n",
    "\n",
    "        # Final layer\n",
    "        self.layer8 = nn.Linear(4096, n_classes) # 後面我自己加的\n",
    "        self.outputs = nn.Conv2d(384, 1, kernel_size=1, padding=0)\n",
    "\n",
    "\n",
    "\n",
    "    # original VGG16\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        vgg16_features = self.layer5(out)\n",
    "        print(vgg16_features.shape)\n",
    "        out = vgg16_features.view(out.size(0), -1)\n",
    "        out = self.layer6(out) # ([2, 4096])\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        # out = self.layer9(out)\n",
    "        # out = self.layer10(out)\n",
    "        # (2, 2) --> ([2, 1, 512, 512])\n",
    "\n",
    "        return  out # ,vgg16_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3e-mmxu0W8gP"
   },
   "outputs": [],
   "source": [
    "#  if __name__== '__main__':\n",
    "#    x = torch.randn((2,3,512,512)) # batch_size, channel, image size, sizes\n",
    "#    f = VGG16()\n",
    "#    f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH2M4yz6cMzs"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qJmHfjDycZ3w"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ynab655BcPj9"
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = (0.6*BCE + 0.4*dice_loss) # 因為BCE小，DICE大，調整至兩者相同\n",
    "\n",
    "        return Dice_BCE\n",
    "\n",
    "class BCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(BCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "\n",
    "        return BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnvHAbVYcP8c"
   },
   "source": [
    "##utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u5T2D4hScSGx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\"\"\" Seeding the randomnseed. \"\"\"\n",
    "def seeding(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\"\"\" Create a directory. \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Calculate the time taken \"\"\"\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hLSHQNfi008"
   },
   "source": [
    "## Data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BqHBJVjwinHf"
   },
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_smaples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Read Image\n",
    "        image = cv2.imread(self.images_path[index],cv2.IMREAD_COLOR)\n",
    "        image = image/255.0 # [512, 512, 3]\n",
    "        image = np.transpose(image, (2,0,1)) # [3, 512, 512]\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        # Read Mask\n",
    "        mask = cv2.imread(self.masks_path[index],cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask/255.0 # [512, 512]\n",
    "        mask = np.expand_dims(mask, axis=0) # [1, 512, 512]\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_smaples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "502S7wc8a7ey"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8FNmVpMRk9oT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZgZM79Ouggpd"
   },
   "outputs": [],
   "source": [
    "# !unzip new_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.Sigmoid()\n",
    "# loss1 = nn.BCELoss()\n",
    "# input1 = torch.randn((3,2), requires_grad=True)\n",
    "# target1 = torch.empty((3,2)).random_(2)\n",
    "# output1 = loss1(m(input1), target1)\n",
    "# output1.backward()\n",
    "# print(output1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "  epoch_loss = 0.0\n",
    "\n",
    "  model.train() # not test, not evaluate\n",
    "  for x, y in loader:\n",
    "    x = x.to(device, dtype = torch.float32)\n",
    "    y = y.to(device, dtype = torch.float32)\n",
    "\n",
    "    # Sets the gradients of all optimized torch.Tensor s to zero.\n",
    "    # 每次更新weights,bias後歸零\n",
    "    optimizer.zero_grad() \n",
    "    y_prediction = model(x) # 模型內沒有sigmoid這邊要嗎?\n",
    "    loss = loss_fn(y_prediction, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss +=loss.item()\n",
    "    # print(y.shape) # 2,1,512,512\n",
    "    # print(y_prediction.shape) # 2,1,512,512\n",
    "\n",
    "  epoch_loss = epoch_loss/len(loader)\n",
    "\n",
    "  return epoch_loss\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "  epoch_loss = 0.0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "     x = x.to(device, dtype = torch.float32)\n",
    "     y = y.to(device, dtype = torch.float32)\n",
    "     \n",
    "     y_prediction = model(x)\n",
    "     loss = loss_fn(y_prediction, y)\n",
    "     epoch_loss +=loss.item()\n",
    "    \n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "nFViG0MTbujW",
    "outputId": "631e9215-4946-4ffe-d1e6-e9dd04254f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:\n",
      "Train: 80 - Valid: 20\n",
      "cuda\n",
      "Valid Loss improved from inf to 0.8422\n",
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.76374\tVal Loss: 0.84222\n",
      "\n",
      "Valid Loss improved from 0.8422 to 0.6172\n",
      "Epoch: 02 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.69183\tVal Loss: 0.61725\n",
      "\n",
      "Valid Loss improved from 0.6172 to 0.5411\n",
      "Epoch: 03 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.60514\tVal Loss: 0.54109\n",
      "\n",
      "Valid Loss improved from 0.5411 to 0.4270\n",
      "Epoch: 04 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.54747\tVal Loss: 0.42701\n",
      "\n",
      "Valid Loss improved from 0.4270 to 0.4034\n",
      "Epoch: 05 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.50755\tVal Loss: 0.40345\n",
      "\n",
      "Valid Loss improved from 0.4034 to 0.3603\n",
      "Epoch: 06 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.47733\tVal Loss: 0.36027\n",
      "\n",
      "Valid Loss improved from 0.3603 to 0.3307\n",
      "Epoch: 07 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.46112\tVal Loss: 0.33069\n",
      "\n",
      "Valid Loss improved from 0.3307 to 0.3115\n",
      "Epoch: 08 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.44569\tVal Loss: 0.31152\n",
      "\n",
      "Valid Loss improved from 0.3115 to 0.3019\n",
      "Epoch: 09 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.43380\tVal Loss: 0.30193\n",
      "\n",
      "Valid Loss improved from 0.3019 to 0.2980\n",
      "Epoch: 10 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.42657\tVal Loss: 0.29803\n",
      "\n",
      "Valid Loss improved from 0.2980 to 0.2900\n",
      "Epoch: 11 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.41965\tVal Loss: 0.28997\n",
      "\n",
      "Valid Loss improved from 0.2900 to 0.2827\n",
      "Epoch: 12 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.41564\tVal Loss: 0.28265\n",
      "\n",
      "Valid Loss improved from 0.2827 to 0.2745\n",
      "Epoch: 13 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.40901\tVal Loss: 0.27454\n",
      "\n",
      "Epoch: 14 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.40376\tVal Loss: 0.27890\n",
      "\n",
      "Valid Loss improved from 0.2745 to 0.2732\n",
      "Epoch: 15 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.40310\tVal Loss: 0.27323\n",
      "\n",
      "Valid Loss improved from 0.2732 to 0.2701\n",
      "Epoch: 16 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.39824\tVal Loss: 0.27015\n",
      "\n",
      "Valid Loss improved from 0.2701 to 0.2662\n",
      "Epoch: 17 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.39697\tVal Loss: 0.26617\n",
      "\n",
      "Valid Loss improved from 0.2662 to 0.2614\n",
      "Epoch: 18 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.39506\tVal Loss: 0.26136\n",
      "\n",
      "Valid Loss improved from 0.2614 to 0.2593\n",
      "Epoch: 19 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.39450\tVal Loss: 0.25927\n",
      "\n",
      "Valid Loss improved from 0.2593 to 0.2588\n",
      "Epoch: 20 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.38796\tVal Loss: 0.25884\n",
      "\n",
      "Valid Loss improved from 0.2588 to 0.2529\n",
      "Epoch: 21 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.38730\tVal Loss: 0.25288\n",
      "\n",
      "Epoch: 22 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.38285\tVal Loss: 0.26332\n",
      "\n",
      "Valid Loss improved from 0.2529 to 0.2502\n",
      "Epoch: 23 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.38941\tVal Loss: 0.25020\n",
      "\n",
      "Valid Loss improved from 0.2502 to 0.2497\n",
      "Epoch: 24 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.38026\tVal Loss: 0.24965\n",
      "\n",
      "Epoch: 25 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.38236\tVal Loss: 0.25264\n",
      "\n",
      "Valid Loss improved from 0.2497 to 0.2493\n",
      "Epoch: 26 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.37893\tVal Loss: 0.24931\n",
      "\n",
      "Valid Loss improved from 0.2493 to 0.2433\n",
      "Epoch: 27 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.37941\tVal Loss: 0.24326\n",
      "\n",
      "Epoch: 28 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.37624\tVal Loss: 0.24516\n",
      "\n",
      "Valid Loss improved from 0.2433 to 0.2385\n",
      "Epoch: 29 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.37411\tVal Loss: 0.23851\n",
      "\n",
      "Epoch: 30 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.37166\tVal Loss: 0.24217\n",
      "\n",
      "Epoch: 31 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.37335\tVal Loss: 0.23860\n",
      "\n",
      "Epoch: 32 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.37013\tVal Loss: 0.24055\n",
      "\n",
      "Epoch: 33 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.36673\tVal Loss: 0.24439\n",
      "\n",
      "Valid Loss improved from 0.2385 to 0.2369\n",
      "Epoch: 34 | Epoch Time: 0m 8s\n",
      "\tTrain Loss: 0.37059\tVal Loss: 0.23694\n",
      "\n",
      "Epoch: 35 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.36615\tVal Loss: 0.24331\n",
      "\n",
      "Epoch: 36 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.36883\tVal Loss: 0.23979\n",
      "\n",
      "Epoch: 37 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.36208\tVal Loss: 0.24423\n",
      "\n",
      "Epoch: 38 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.36139\tVal Loss: 0.23860\n",
      "\n",
      "Epoch: 39 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35974\tVal Loss: 0.24977\n",
      "\n",
      "Epoch: 40 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35945\tVal Loss: 0.24007\n",
      "\n",
      "Epoch: 41 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35689\tVal Loss: 0.24276\n",
      "\n",
      "Epoch: 42 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35485\tVal Loss: 0.25338\n",
      "\n",
      "Epoch: 43 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.34980\tVal Loss: 0.23958\n",
      "\n",
      "Epoch: 44 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35283\tVal Loss: 0.24051\n",
      "\n",
      "Epoch: 45 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.35146\tVal Loss: 0.24774\n",
      "\n",
      "Epoch: 46 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.34756\tVal Loss: 0.23699\n",
      "\n",
      "Epoch: 47 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.34081\tVal Loss: 0.24601\n",
      "\n",
      "Epoch: 48 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.34218\tVal Loss: 0.24555\n",
      "\n",
      "Epoch: 49 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.34280\tVal Loss: 0.25208\n",
      "\n",
      "Epoch: 50 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.33949\tVal Loss: 0.26802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # fixed\n",
    "    seeding(42)\n",
    "\n",
    "    # file\n",
    "    create_dir('C:/Users/User/Desktop/UNet/files')\n",
    "\n",
    "\n",
    "    # create_dir('/content/files')\n",
    "\n",
    "    # Load data\n",
    "    train_x = sorted(glob(\"C://Users//User//Desktop//UNet//new_data//train//images//*\"))\n",
    "    train_y = sorted(glob(\"C://Users//User//Desktop//UNet//new_data//train//mask//*\"))\n",
    "    valid_x = sorted(glob(\"C://Users//User//Desktop//UNet//new_data//test//images//*\"))\n",
    "    valid_y = sorted(glob(\"C://Users//User//Desktop//UNet//new_data//test//mask//*\"))\n",
    "\n",
    "    # train_x = sorted(glob(\"../content/new_data/train/images/*\"))\n",
    "    # train_y = sorted(glob(\"../content/new_data/train/mask/*\"))\n",
    "    # valid_x = sorted(glob(\"../content/new_data/test/images/*\"))\n",
    "    # valid_y = sorted(glob(\"../content/new_data/test/mask/*\"))\n",
    "\n",
    "    # Check data size\n",
    "    data_str = f\"Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\"\n",
    "    print(data_str)\n",
    "\n",
    "    # Hyperparameters\n",
    "    H,W = 512,512\n",
    "    size = (H,W)\n",
    "    batch_size = 2\n",
    "    num_epoch = 50\n",
    "    lr =  1e-4 # UNet 1e-4 # VGG 1e-3\n",
    "    checkpoint_path = \"C:/Users/User/Desktop/UNet/files/checkpoint.pth\"\n",
    "\n",
    "    # Dataset and Loader\n",
    "    train_dataset = DriveDataset(train_x, train_y)\n",
    "    valid_dataset = DriveDataset(valid_x, valid_y)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "      dataset = train_dataset,\n",
    "      batch_size = batch_size,\n",
    "      shuffle = True,\n",
    "      num_workers = 0\n",
    "    )\n",
    "\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "      dataset = valid_dataset,\n",
    "      batch_size = batch_size,\n",
    "      shuffle = False,\n",
    "      num_workers = 0\n",
    "    )\n",
    "\n",
    "    # device = torch.device('cpu') # 'cuda'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "\n",
    "    # loss_fn = BCELoss()\n",
    "    loss_fn = DiceLoss()\n",
    "    # loss_fn = nn.BCEWithLogitsLoss()\n",
    "    # loss_fn = DiceBCELoss()\n",
    "\n",
    "\n",
    "    loss_list_train =[]\n",
    "    loss_list_val =[]\n",
    "\n",
    "\n",
    "    # Strat Training\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "        loss_list_train.append(train_loss)\n",
    "        loss_list_val.append(valid_loss)\n",
    "\n",
    "\n",
    "        # Save better model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            data_str = f'Valid Loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}'\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        mins, secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {mins}m {secs}s\\n'\n",
    "        data_str += f'\\tTrain Loss: {train_loss:.5f}'\n",
    "        data_str += f'\\tVal Loss: {valid_loss:.5f}\\n'\n",
    "        print(data_str)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('VGG_mixed.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(zip(loss_list_train, loss_list_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkLvD5ooz9aH"
   },
   "source": [
    "## Test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYFE2cdql81L"
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "from operator import add\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfQsRwzBAQsV"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5  # 把>0.5的當作有，只計算有的(偽陽性)，或許可以計算沒有的\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3) # 和彩色圖片(test data)同樣維度\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMjpvETR3ivo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.6560 - F1: 0.7917 - Recall: 0.7773 - Precision: 0.8154 - Acc: 0.9646\n",
      "FPS:  180.68538294856828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # fixed\n",
    "    seeding(42)\n",
    "\n",
    "    # file\n",
    "    create_dir('C:/Users/User/Desktop/UNet/results')\n",
    "\n",
    "    # create_dir('/content/results')\n",
    "\n",
    "    # Testing set\n",
    "    test_x = sorted(glob(\"C:/Users/User/Desktop/UNet/new_data/test/images/*\"))\n",
    "    test_y = sorted(glob(\"C:/Users/User/Desktop/UNet/new_data/test/mask/*\"))\n",
    "\n",
    "\n",
    "    # test_x = sorted(glob(\"../content/new_data/test/images/*\"))\n",
    "    # test_y = sorted(glob(\"../content/new_data/test/mask/*\"))\n",
    "\n",
    "    # Hyperparameters\n",
    "    H,W = 512,512\n",
    "    size = (H,W)\n",
    "    checkpoint_path = \"C:/Users/User/Desktop/UNet/files/checkpoint.pth\"\n",
    "\n",
    "    # Load checkpoint\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = build_unet()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict((torch.load(checkpoint_path, map_location = device))) # 載入訓練好的模型\n",
    "    model.eval() # Set the mode\n",
    "\n",
    "    metrics_score = [0,0,0,0,0]\n",
    "    time_taken = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Read image\"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "        x = np.transpose(image, (2, 0, 1)) ## (3, 512, 512)\n",
    "        x = x/255.0\n",
    "        x = np.expand_dims(x, axis=0) ## (1, 3, 512, 512) 為了在一個batch裡面?\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading mask \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "        y = np.expand_dims(mask, axis=0) ## (1, 512, 512)\n",
    "        y = y/255.0\n",
    "        y = np.expand_dims(y, axis=0) ## (1, 1, 512, 512)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            pred_y = model(x)\n",
    "            pred_y = torch.sigmoid(pred_y) # 其他都沒加這個\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "            score = calculate_metrics(y, pred_y)\n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            \n",
    "            pred_y = pred_y[0].cpu().numpy() ## (1, 512, 512)\n",
    "            pred_y = np.squeeze(pred_y, axis=0) ## (512, 512)\n",
    "            pred_y = pred_y > 0.5\n",
    "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "            \"\"\" Saving masks \"\"\"\n",
    "            ori_mask = mask_parse(mask) # 正確\n",
    "            pred_y = mask_parse(pred_y) # 預測\n",
    "            line = np.ones((size[1], 10, 3)) * 128 # 產生一條線\n",
    "\n",
    "            cat_images = np.concatenate(\n",
    "                [image, line, ori_mask, line, pred_y * 255], axis=1\n",
    "            )\n",
    "            # 儲存圖片\n",
    "            cv2.imwrite(f\"C:/Users/User/Desktop/UNet/results/{name}.png\", cat_images)\n",
    "\n",
    "\n",
    "    # 計算平均分數\n",
    "    jaccard = metrics_score[0]/len(test_x)\n",
    "    f1 = metrics_score[1]/len(test_x)\n",
    "    recall = metrics_score[2]/len(test_x)\n",
    "    precision = metrics_score[3]/len(test_x)\n",
    "    acc = metrics_score[4]/len(test_x)\n",
    "    print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n",
    "\n",
    "    fps = 1/np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)\n",
    "\n",
    "    scores = [jaccard, f1, recall, precision, acc]\n",
    "    np.savetxt(\"C:/Users/User/Desktop/UNet/results/metrics_score.csv\", scores, delimiter =\",\",fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "xsZbxSlrTvAZ"
   ],
   "name": "UNet.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
